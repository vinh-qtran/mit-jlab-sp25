{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# NEW: we will use ks_2samp for a simple statistical test on Kd distributions\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# define matplotlib style\n",
    "mpl.style.use(\"classic\")\n",
    "mpl.rc(\"xtick\", labelsize=15)\n",
    "mpl.rc(\"ytick\", labelsize=15)\n",
    "mpl.rc(\"xtick.major\", size=14, width=2)\n",
    "mpl.rc(\"xtick.minor\", size=7, width=2, visible=True)\n",
    "mpl.rc(\"ytick.major\", size=14, width=2)\n",
    "mpl.rc(\"ytick.minor\", size=7, width=2, visible=True)\n",
    "mpl.rc(\"lines\", linewidth=2, markersize=5)\n",
    "mpl.rc(\"axes\", linewidth=2, labelsize=15, labelpad=2.5)\n",
    "mpl.rc(\"legend\", fontsize=15, loc=\"best\", frameon=True, numpoints=1)\n",
    "\n",
    "mpl.rc(\"font\", family=\"STIXGeneral\")\n",
    "mpl.rc(\"mathtext\", fontset=\"stix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "INPUT_FILE = 'FileC004.txt'   \n",
    "ALL_OUT   = 'all_events_with_toggle.csv'\n",
    "COIN_OUT  = 'coincident_events_with_toggle.csv'\n",
    "\n",
    "records = []\n",
    "with open(INPUT_FILE, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=None, skipinitialspace=True)\n",
    "    for row in reader:\n",
    "        if not row or row[0].startswith('#'):\n",
    "            continue\n",
    "        # ensure we have at least 11 columns\n",
    "        if len(row) < 11:\n",
    "            continue\n",
    "\n",
    "        # parse fields\n",
    "        event_time = row[1].strip()       # e.g. \"0:00:07\"\n",
    "        event_date = row[2].strip()       # e.g. \"1/1/2019\"\n",
    "        ts_ms      = int(row[3])          # TimeStamp[ms]\n",
    "        coin       = int(row[10])         # Coincident flag\n",
    "\n",
    "        # compute toggle bit\n",
    "        toggle = ts_ms % 2\n",
    "\n",
    "        records.append({\n",
    "            'Date':           event_date,\n",
    "            'Time':           event_time,\n",
    "            'TimeStamp_ms':   ts_ms,\n",
    "            'toggle':         toggle,\n",
    "            'Coincident':     coin,\n",
    "        })\n",
    "\n",
    "# build DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# reconstruct full datetime and compute diffs\n",
    "# assume Date in M/D/YYYY and Time in H:M:S\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'],\n",
    "                                format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# sort just in case\n",
    "df.sort_values('DateTime', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Δ from Timestamp_ms\n",
    "df['Δts_ms'] = df['TimeStamp_ms'].diff()\n",
    "\n",
    "# Δ from actual datetime (in ms)\n",
    "df['Δdt_ms'] = df['DateTime'].diff().dt.total_seconds() * 1000\n",
    "\n",
    "# consistency check: flag large mismatches\n",
    "df['ts_match'] = (df['Δts_ms'] - df['Δdt_ms']).abs() < 1.0  # allow ±1 ms\n",
    "\n",
    "# save all events\n",
    "df.to_csv(ALL_OUT, index=False)\n",
    "print(f\"Wrote {len(df)} events to {ALL_OUT}\")\n",
    "\n",
    "# save only coincidences\n",
    "df_coin = df[df['Coincident'] == 1]\n",
    "df_coin.to_csv(COIN_OUT, index=False)\n",
    "print(f\"Wrote {len(df_coin)} coincident events to {COIN_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1243d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- 0) Define your mapping: filename → angle (in degrees) ------------\n",
    "# e.g. {'coin_0deg.csv': 0, 'coin_30deg.csv': 30, ...}\n",
    "file_to_angle = {\n",
    "    'coincidence_0deg.csv':   0,\n",
    "    'coincidence_15deg.csv':  15,\n",
    "    'coincidence_30deg.csv':  30,\n",
    "    'coincidence_45deg.csv':  45,\n",
    "    'coincidence_60deg.csv':  60,\n",
    "    'coincidence_75deg.csv':  75,\n",
    "    'coincidence_90deg.csv':  90,\n",
    "    # add as many as you have...\n",
    "}\n",
    "\n",
    "# --- 1) Load all‑events toggle bits ----------------------------------\n",
    "all_df = pd.read_csv('all_events_with_toggle.csv')             # contains 'toggle'\n",
    "bits = all_df['toggle'].astype(int).values\n",
    "n = len(bits)\n",
    "\n",
    "# --- 2) Basic randomness tests on all‑events ------------------------\n",
    "# Monobit\n",
    "ones = bits.sum()\n",
    "p_hat = ones / n\n",
    "z = (p_hat - 0.5) / np.sqrt(0.25 / n)\n",
    "p_val_freq = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "print(f\"Monobit: 1s={ones}/{n}, p̂={p_hat:.4f}, p‑value={p_val_freq:.3f}\")\n",
    "\n",
    "# Runs\n",
    "runs = 1 + np.sum(bits[1:] != bits[:-1])\n",
    "mu_runs = 2*n*p_hat*(1-p_hat) + 1\n",
    "var_runs = (2*n*p_hat*(1-p_hat)*(2*n*p_hat*(1-p_hat)-n*p_hat*(1-p_hat)))/(n**2*(n-1))\n",
    "z_runs = (runs - mu_runs) / np.sqrt(var_runs)\n",
    "p_val_runs = 2 * (1 - stats.norm.cdf(abs(z_runs)))\n",
    "print(f\"Runs: runs={runs}, E[runs]={mu_runs:.1f}, p‑value={p_val_runs:.3f}\")\n",
    "\n",
    "# Serial (2‑bit)\n",
    "pairs = bits.reshape(-1, 2)\n",
    "pair_vals = pairs[:,0]*2 + pairs[:,1]\n",
    "counts = np.bincount(pair_vals, minlength=4)\n",
    "expected = len(pair_vals)/4\n",
    "chi2_serial = ((counts-expected)**2/expected).sum()\n",
    "p_val_serial = 1 - stats.chi2.cdf(chi2_serial, df=3)\n",
    "print(f\"Serial: counts={counts.tolist()}, p‑value={p_val_serial:.3f}\")\n",
    "\n",
    "# Lag‑1 autocorrelation\n",
    "autocorr1 = np.corrcoef(bits[:-1], bits[1:])[0,1]\n",
    "print(f\"Lag‑1 autocorr: {autocorr1:.4f}\")\n",
    "\n",
    "# Byte χ²\n",
    "m = (n//8)*8\n",
    "bytes_arr = np.packbits(bits[:m].reshape(-1,8), axis=1).flatten()\n",
    "freqs = np.bincount(bytes_arr, minlength=256)\n",
    "chi2_bytes = ((freqs - m/256)**2/(m/256)).sum()\n",
    "p_val_bytes = 1 - stats.chi2.cdf(chi2_bytes, df=255)\n",
    "print(f\"Byte χ²: p‑value={p_val_bytes:.3f}\")\n",
    "\n",
    "# --- 3) Build a combined coin_df with angles -------------------------\n",
    "coin_frames = []\n",
    "for fname, angle in file_to_angle.items():\n",
    "    if not os.path.exists(fname):\n",
    "        print(f\"Warning: {fname} not found, skipping.\")\n",
    "        continue\n",
    "    df = pd.read_csv(fname)                          # JLExp56.pdf](file-service://file-TZRdpPZV1dpyvPH7vCuSsM)\n",
    "    df['angle'] = angle                              # attach angle\n",
    "    coin_frames.append(df[['toggle','angle']])\n",
    "\n",
    "if not coin_frames:\n",
    "    raise RuntimeError(\"No coincidence files loaded: check your file_to_angle mapping.\")\n",
    "\n",
    "coin_df = pd.concat(coin_frames, ignore_index=True)\n",
    "angles  = coin_df['angle'].values\n",
    "toggles = coin_df['toggle'].astype(int).values\n",
    "N_coin  = len(angles)\n",
    "\n",
    "# --- 4) Angle vs toggle independence tests ---------------------------\n",
    "# 4a) Point‑biserial correlation\n",
    "r_pb, p_pb = stats.pointbiserialr(toggles, angles)\n",
    "print(f\"Point‑biserial corr: r={r_pb:.4f}, p‑value={p_pb:.3f}\")\n",
    "\n",
    "# 4b) χ² test of independence (bin angles)\n",
    "bins = np.linspace(0, 360, 13)  # 12 bins of 30°\n",
    "angle_bin = pd.cut(angles, bins, include_lowest=True)\n",
    "cont = pd.crosstab(angle_bin, toggles)\n",
    "chi2_ind, p_ind, dof, exp = stats.chi2_contingency(cont)\n",
    "print(f\"Chi‑sq indep: χ²={chi2_ind:.1f}, p‑value={p_ind:.3f}, dof={dof}\")\n",
    "\n",
    "print(\"\\nContingency table (angle_bin × toggle):\")\n",
    "print(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecab90e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u273f' in position 74: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     85\u001b[0m pdf\u001b[38;5;241m.\u001b[39msection_body(clean_unicode(\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- We process things differently – and that’s totally okay\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- We’re a team, not opponents\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- We’re not fixing each other – we’re learning how to meet in the middle with love and patience\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m ))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Save the PDF\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCozy_Communication_Toolkit.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCozy_Communication_Toolkit.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:1065\u001b[0m, in \u001b[0;36mFPDF.output\u001b[0;34m(self, name, dest)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m#Finish document if necessary\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m-> 1065\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m dest\u001b[38;5;241m=\u001b[39mdest\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dest\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:246\u001b[0m, in \u001b[0;36mFPDF.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpage()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m#close document\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enddoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:1636\u001b[0m, in \u001b[0;36mFPDF._enddoc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_enddoc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putheader()\n\u001b[0;32m-> 1636\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_putpages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putresources()\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;66;03m#Info\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:1170\u001b[0m, in \u001b[0;36mFPDF._putpages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m#Page content\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress:\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# manage binary data as latin1 until PEP461 or similar is implemented\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m PY3K \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages[n] \n\u001b[1;32m   1171\u001b[0m     p \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcompress(p)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u273f' in position 74: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import scipy.stats as stats\n",
    "\n",
    "# ─── 1) Load data ────────────────────────────────────────────────────────────\n",
    "all_df  = pd.read_csv('all_events_with_toggle.csv')             # JLExp56.pdf](file-service://file-TZRdpPZV1dpyvPH7vCuSsM)\n",
    "file_to_angle = {\n",
    "    'coincidence_0deg.csv':   0,\n",
    "    'coincidence_30deg.csv': 30,\n",
    "    'coincidence_60deg.csv': 60,\n",
    "    'coincidence_90deg.csv': 90,\n",
    "    # …etc.\n",
    "}\n",
    "coin_frames = []\n",
    "for fname, angle in file_to_angle.items():\n",
    "    df = pd.read_csv(fname)                                     # JLExp56.pdf](file-service://file-TZRdpPZV1dpyvPH7vCuSsM)\n",
    "    df['angle'] = angle\n",
    "    coin_frames.append(df[['toggle','angle']])\n",
    "coin_df = pd.concat(coin_frames, ignore_index=True)\n",
    "\n",
    "bits    = all_df['toggle'].astype(int).values\n",
    "toggles = coin_df['toggle'].astype(int).values\n",
    "angles  = coin_df['angle'].values\n",
    "\n",
    "# ─── 2) Bit‑value Histogram ─────────────────────────────────────────────────\n",
    "plt.figure()\n",
    "counts = [np.sum(bits==0), np.sum(bits==1)]\n",
    "plt.bar([0,1], counts, width=0.4)\n",
    "plt.xticks([0,1])\n",
    "plt.xlabel('Bit value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Monobit Histogram')\n",
    "plt.savefig('plot_monobit_histogram.png', dpi=150)\n",
    "\n",
    "# ─── 3) Running Frequency over Time ──────────────────────────────────────────\n",
    "plt.figure()\n",
    "cum_frac = np.cumsum(bits) / np.arange(1, len(bits)+1)\n",
    "plt.plot(cum_frac)\n",
    "plt.axhline(0.5, linestyle='--', label='0.5')\n",
    "plt.xlabel('Event index')\n",
    "plt.ylabel('Cumulative fraction of 1’s')\n",
    "plt.title('Cumulative Frequency of 1’s')\n",
    "plt.legend()\n",
    "plt.savefig('plot_running_frequency.png', dpi=150)\n",
    "\n",
    "# ─── 4) Run‑Length Distribution ──────────────────────────────────────────────\n",
    "# compute run lengths\n",
    "run_vals = np.split(bits, np.where(bits[:-1] != bits[1:])[0]+1)\n",
    "run_lengths = [len(r) for r in run_vals]\n",
    "plt.figure()\n",
    "plt.hist(run_lengths, bins=50)\n",
    "plt.xlabel('Run length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Run‑Length Distribution')\n",
    "plt.savefig('plot_run_length.png', dpi=150)\n",
    "\n",
    "# ─── 5) Autocorrelation Function ────────────────────────────────────────────\n",
    "plt.figure()\n",
    "ac = acf(bits, nlags=50, fft=True)\n",
    "plt.stem(range(len(ac)), ac, use_line_collection=True)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Bitstream ACF')\n",
    "plt.savefig('plot_autocorrelation.png', dpi=150)\n",
    "\n",
    "# ─── 6) Serial 2‑Bit Frequencies ─────────────────────────────────────────────\n",
    "pairs = bits[:(len(bits)//2)*2].reshape(-1,2)\n",
    "pair_vals = pairs[:,0]*2 + pairs[:,1]\n",
    "labels = ['00','01','10','11']\n",
    "counts2 = np.bincount(pair_vals, minlength=4)\n",
    "plt.figure()\n",
    "plt.bar(labels, counts2)\n",
    "plt.xlabel('2‑bit tuple')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Serial (2‑bit) Frequencies')\n",
    "plt.savefig('plot_serial_frequencies.png', dpi=150)\n",
    "\n",
    "# ─── 7) Toggle–Angle Scatter Plot ────────────────────────────────────────────\n",
    "plt.figure()\n",
    "y_jitter = toggles + (np.random.rand(len(toggles)) - 0.5)*0.1\n",
    "plt.scatter(angles, y_jitter, s=5, alpha=0.3)\n",
    "plt.yticks([0,1])\n",
    "plt.xlabel('Angle (deg)')\n",
    "plt.ylabel('Toggle bit (jittered)')\n",
    "plt.title('Toggle vs Angle Scatter')\n",
    "plt.savefig('plot_toggle_angle_scatter.png', dpi=150)\n",
    "\n",
    "# ─── 8) Toggle‑Rate by Angle‑Bin ─────────────────────────────────────────────\n",
    "bins = np.linspace(0,360,13)\n",
    "df = pd.DataFrame({'angle': angles, 'toggle': toggles})\n",
    "grp = df.groupby(pd.cut(df.angle, bins)).toggle.mean()\n",
    "plt.figure()\n",
    "grp.plot.bar()\n",
    "plt.ylabel('P(toggle=1)')\n",
    "plt.xlabel('Angle bin')\n",
    "plt.title('Toggle‑Rate by Angle Bin')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_toggle_rate_by_angle_bin.png', dpi=150)\n",
    "\n",
    "# ─── 9) Inter‑arrival Times Histogram & Exponential Fit ─────────────────────\n",
    "# need Δts_ms from all_df (you saved it previously)\n",
    "dt = all_df['Δts_ms'].dropna().values\n",
    "lam = 1/np.mean(dt)  # estimated rate (per ms)\n",
    "plt.figure()\n",
    "plt.hist(dt, bins=50, density=True, alpha=0.6)\n",
    "x = np.linspace(0, dt.max(), 300)\n",
    "plt.plot(x, lam * np.exp(-lam*x), label=f'Exp(λ={lam:.3f} ms⁻¹)')\n",
    "plt.xlabel('Δts (ms)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Inter‑arrival Time Histogram')\n",
    "plt.legend()\n",
    "plt.savefig('plot_interval_histogram.png', dpi=150)\n",
    "\n",
    "# ─── 10) Q–Q Plot vs Exponential ─────────────────────────────────────────────\n",
    "plt.figure()\n",
    "stats.probplot(dt, dist=stats.expon(scale=1/lam), plot=plt)\n",
    "plt.title('Q–Q Plot vs Exponential')\n",
    "plt.savefig('plot_qq_exponential.png', dpi=150)\n",
    "\n",
    "print(\"All plots saved as PNGs.\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
